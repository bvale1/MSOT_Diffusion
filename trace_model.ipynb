{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9db986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in ./venv/lib/python3.12/site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvista\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import denoising_diffusion_pytorch as ddp\n",
    "from functools import partial\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "from edm2.training.networks_edm2 import Precond\n",
    "from edm2.training.networks_edm2 import UNet as EDM2_UNet\n",
    "\n",
    "import end_to_end_phantom_QPAT.utils.networks as e2eQPAT_networks\n",
    "import utility_functions as uf\n",
    "from epoch_steps import *\n",
    "from nn_modules.time_conditioned_residual_unet import TimeConditionedResUNet\n",
    "from nn_modules.DiT import DiT\n",
    "from nn_modules.swin_unet import SwinTransformerSys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60cbb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments (from uf.get_config() in run_model.py)\n",
    "model_name = 'UNet_diffusion_ablation'  # options: 'UNet_e2eQPAT', 'EDM2', 'UNet_wl_pos_emb', 'UNet_diffusion_ablation', 'Swin_UNet', 'DiT'\n",
    "#model_name = 'UNet_e2eQPAT'  # options: 'UNet_e2eQPAT', 'EDM2', 'UNet_wl_pos_emb', 'UNet_diffusion_ablation', 'Swin_UNet', 'DiT'\n",
    "image_size = 288\n",
    "channels = 1\n",
    "predict_fluence = True\n",
    "attention = False\n",
    "use_torchsummary = True\n",
    "use_torchvista = False # torchvista currently does not support some layers\n",
    "col_names = [\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f4e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "UNet                                     [32, 1, 288, 288]         [32, 2, 288, 288]         1                         --\n",
      "├─ModuleDict: 1-1                        --                        --                        --                        --\n",
      "│    └─MPConv: 2-1                       [32, 2, 288, 288]         [32, 64, 288, 288]        1,152                     --\n",
      "│    └─Block: 2-2                        [32, 64, 288, 288]        [32, 64, 288, 288]        1                         --\n",
      "│    │    └─MPConv: 3-1                  [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    │    └─MPConv: 3-2                  [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    └─Block: 2-3                        [32, 64, 288, 288]        [32, 64, 288, 288]        1                         --\n",
      "│    │    └─MPConv: 3-3                  [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    │    └─MPConv: 3-4                  [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    └─Block: 2-4                        [32, 64, 288, 288]        [32, 64, 288, 288]        1                         --\n",
      "│    │    └─MPConv: 3-5                  [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    │    └─MPConv: 3-6                  [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    └─Block: 2-5                        [32, 64, 288, 288]        [32, 64, 144, 144]        1                         --\n",
      "│    │    └─MPConv: 3-7                  [32, 64, 144, 144]        [32, 64, 144, 144]        36,864                    --\n",
      "│    │    └─MPConv: 3-8                  [32, 64, 144, 144]        [32, 64, 144, 144]        36,864                    --\n",
      "│    └─Block: 2-6                        [32, 64, 144, 144]        [32, 128, 144, 144]       1                         --\n",
      "│    │    └─MPConv: 3-9                  [32, 64, 144, 144]        [32, 128, 144, 144]       8,192                     --\n",
      "│    │    └─MPConv: 3-10                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    │    └─MPConv: 3-11                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    └─Block: 2-7                        [32, 128, 144, 144]       [32, 128, 144, 144]       1                         --\n",
      "│    │    └─MPConv: 3-12                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    │    └─MPConv: 3-13                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    └─Block: 2-8                        [32, 128, 144, 144]       [32, 128, 144, 144]       1                         --\n",
      "│    │    └─MPConv: 3-14                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    │    └─MPConv: 3-15                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    └─Block: 2-9                        [32, 128, 144, 144]       [32, 128, 72, 72]         1                         --\n",
      "│    │    └─MPConv: 3-16                 [32, 128, 72, 72]         [32, 128, 72, 72]         147,456                   --\n",
      "│    │    └─MPConv: 3-17                 [32, 128, 72, 72]         [32, 128, 72, 72]         147,456                   --\n",
      "│    └─Block: 2-10                       [32, 128, 72, 72]         [32, 192, 72, 72]         1                         --\n",
      "│    │    └─MPConv: 3-18                 [32, 128, 72, 72]         [32, 192, 72, 72]         24,576                    --\n",
      "│    │    └─MPConv: 3-19                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    │    └─MPConv: 3-20                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    └─Block: 2-11                       [32, 192, 72, 72]         [32, 192, 72, 72]         1                         --\n",
      "│    │    └─MPConv: 3-21                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    │    └─MPConv: 3-22                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    └─Block: 2-12                       [32, 192, 72, 72]         [32, 192, 72, 72]         1                         --\n",
      "│    │    └─MPConv: 3-23                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    │    └─MPConv: 3-24                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    └─Block: 2-13                       [32, 192, 72, 72]         [32, 192, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-25                 [32, 192, 36, 36]         [32, 192, 36, 36]         331,776                   --\n",
      "│    │    └─MPConv: 3-26                 [32, 192, 36, 36]         [32, 192, 36, 36]         331,776                   --\n",
      "│    └─Block: 2-14                       [32, 192, 36, 36]         [32, 256, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-27                 [32, 192, 36, 36]         [32, 256, 36, 36]         49,152                    --\n",
      "│    │    └─MPConv: 3-28                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    │    └─MPConv: 3-29                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    └─Block: 2-15                       [32, 256, 36, 36]         [32, 256, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-30                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    │    └─MPConv: 3-31                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    └─Block: 2-16                       [32, 256, 36, 36]         [32, 256, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-32                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    │    └─MPConv: 3-33                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "├─ModuleDict: 1-2                        --                        --                        --                        --\n",
      "│    └─Block: 2-17                       [32, 256, 36, 36]         [32, 256, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-34                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    │    └─MPConv: 3-35                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    └─Block: 2-18                       [32, 256, 36, 36]         [32, 256, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-36                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    │    └─MPConv: 3-37                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    └─Block: 2-19                       [32, 512, 36, 36]         [32, 256, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-38                 [32, 512, 36, 36]         [32, 256, 36, 36]         1,179,648                 --\n",
      "│    │    └─MPConv: 3-39                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    │    └─MPConv: 3-40                 [32, 512, 36, 36]         [32, 256, 36, 36]         131,072                   --\n",
      "│    └─Block: 2-20                       [32, 512, 36, 36]         [32, 256, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-41                 [32, 512, 36, 36]         [32, 256, 36, 36]         1,179,648                 --\n",
      "│    │    └─MPConv: 3-42                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    │    └─MPConv: 3-43                 [32, 512, 36, 36]         [32, 256, 36, 36]         131,072                   --\n",
      "│    └─Block: 2-21                       [32, 512, 36, 36]         [32, 256, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-44                 [32, 512, 36, 36]         [32, 256, 36, 36]         1,179,648                 --\n",
      "│    │    └─MPConv: 3-45                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    │    └─MPConv: 3-46                 [32, 512, 36, 36]         [32, 256, 36, 36]         131,072                   --\n",
      "│    └─Block: 2-22                       [32, 448, 36, 36]         [32, 256, 36, 36]         1                         --\n",
      "│    │    └─MPConv: 3-47                 [32, 448, 36, 36]         [32, 256, 36, 36]         1,032,192                 --\n",
      "│    │    └─MPConv: 3-48                 [32, 256, 36, 36]         [32, 256, 36, 36]         589,824                   --\n",
      "│    │    └─MPConv: 3-49                 [32, 448, 36, 36]         [32, 256, 36, 36]         114,688                   --\n",
      "│    └─Block: 2-23                       [32, 256, 36, 36]         [32, 256, 72, 72]         1                         --\n",
      "│    │    └─MPConv: 3-50                 [32, 256, 72, 72]         [32, 256, 72, 72]         589,824                   --\n",
      "│    │    └─MPConv: 3-51                 [32, 256, 72, 72]         [32, 256, 72, 72]         589,824                   --\n",
      "│    └─Block: 2-24                       [32, 448, 72, 72]         [32, 192, 72, 72]         1                         --\n",
      "│    │    └─MPConv: 3-52                 [32, 448, 72, 72]         [32, 192, 72, 72]         774,144                   --\n",
      "│    │    └─MPConv: 3-53                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    │    └─MPConv: 3-54                 [32, 448, 72, 72]         [32, 192, 72, 72]         86,016                    --\n",
      "│    └─Block: 2-25                       [32, 384, 72, 72]         [32, 192, 72, 72]         1                         --\n",
      "│    │    └─MPConv: 3-55                 [32, 384, 72, 72]         [32, 192, 72, 72]         663,552                   --\n",
      "│    │    └─MPConv: 3-56                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    │    └─MPConv: 3-57                 [32, 384, 72, 72]         [32, 192, 72, 72]         73,728                    --\n",
      "│    └─Block: 2-26                       [32, 384, 72, 72]         [32, 192, 72, 72]         1                         --\n",
      "│    │    └─MPConv: 3-58                 [32, 384, 72, 72]         [32, 192, 72, 72]         663,552                   --\n",
      "│    │    └─MPConv: 3-59                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    │    └─MPConv: 3-60                 [32, 384, 72, 72]         [32, 192, 72, 72]         73,728                    --\n",
      "│    └─Block: 2-27                       [32, 320, 72, 72]         [32, 192, 72, 72]         1                         --\n",
      "│    │    └─MPConv: 3-61                 [32, 320, 72, 72]         [32, 192, 72, 72]         552,960                   --\n",
      "│    │    └─MPConv: 3-62                 [32, 192, 72, 72]         [32, 192, 72, 72]         331,776                   --\n",
      "│    │    └─MPConv: 3-63                 [32, 320, 72, 72]         [32, 192, 72, 72]         61,440                    --\n",
      "│    └─Block: 2-28                       [32, 192, 72, 72]         [32, 192, 144, 144]       1                         --\n",
      "│    │    └─MPConv: 3-64                 [32, 192, 144, 144]       [32, 192, 144, 144]       331,776                   --\n",
      "│    │    └─MPConv: 3-65                 [32, 192, 144, 144]       [32, 192, 144, 144]       331,776                   --\n",
      "│    └─Block: 2-29                       [32, 320, 144, 144]       [32, 128, 144, 144]       1                         --\n",
      "│    │    └─MPConv: 3-66                 [32, 320, 144, 144]       [32, 128, 144, 144]       368,640                   --\n",
      "│    │    └─MPConv: 3-67                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    │    └─MPConv: 3-68                 [32, 320, 144, 144]       [32, 128, 144, 144]       40,960                    --\n",
      "│    └─Block: 2-30                       [32, 256, 144, 144]       [32, 128, 144, 144]       1                         --\n",
      "│    │    └─MPConv: 3-69                 [32, 256, 144, 144]       [32, 128, 144, 144]       294,912                   --\n",
      "│    │    └─MPConv: 3-70                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    │    └─MPConv: 3-71                 [32, 256, 144, 144]       [32, 128, 144, 144]       32,768                    --\n",
      "│    └─Block: 2-31                       [32, 256, 144, 144]       [32, 128, 144, 144]       1                         --\n",
      "│    │    └─MPConv: 3-72                 [32, 256, 144, 144]       [32, 128, 144, 144]       294,912                   --\n",
      "│    │    └─MPConv: 3-73                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    │    └─MPConv: 3-74                 [32, 256, 144, 144]       [32, 128, 144, 144]       32,768                    --\n",
      "│    └─Block: 2-32                       [32, 192, 144, 144]       [32, 128, 144, 144]       1                         --\n",
      "│    │    └─MPConv: 3-75                 [32, 192, 144, 144]       [32, 128, 144, 144]       221,184                   --\n",
      "│    │    └─MPConv: 3-76                 [32, 128, 144, 144]       [32, 128, 144, 144]       147,456                   --\n",
      "│    │    └─MPConv: 3-77                 [32, 192, 144, 144]       [32, 128, 144, 144]       24,576                    --\n",
      "│    └─Block: 2-33                       [32, 128, 144, 144]       [32, 128, 288, 288]       1                         --\n",
      "│    │    └─MPConv: 3-78                 [32, 128, 288, 288]       [32, 128, 288, 288]       147,456                   --\n",
      "│    │    └─MPConv: 3-79                 [32, 128, 288, 288]       [32, 128, 288, 288]       147,456                   --\n",
      "│    └─Block: 2-34                       [32, 192, 288, 288]       [32, 64, 288, 288]        1                         --\n",
      "│    │    └─MPConv: 3-80                 [32, 192, 288, 288]       [32, 64, 288, 288]        110,592                   --\n",
      "│    │    └─MPConv: 3-81                 [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    │    └─MPConv: 3-82                 [32, 192, 288, 288]       [32, 64, 288, 288]        12,288                    --\n",
      "│    └─Block: 2-35                       [32, 128, 288, 288]       [32, 64, 288, 288]        1                         --\n",
      "│    │    └─MPConv: 3-83                 [32, 128, 288, 288]       [32, 64, 288, 288]        73,728                    --\n",
      "│    │    └─MPConv: 3-84                 [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    │    └─MPConv: 3-85                 [32, 128, 288, 288]       [32, 64, 288, 288]        8,192                     --\n",
      "│    └─Block: 2-36                       [32, 128, 288, 288]       [32, 64, 288, 288]        1                         --\n",
      "│    │    └─MPConv: 3-86                 [32, 128, 288, 288]       [32, 64, 288, 288]        73,728                    --\n",
      "│    │    └─MPConv: 3-87                 [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    │    └─MPConv: 3-88                 [32, 128, 288, 288]       [32, 64, 288, 288]        8,192                     --\n",
      "│    └─Block: 2-37                       [32, 128, 288, 288]       [32, 64, 288, 288]        1                         --\n",
      "│    │    └─MPConv: 3-89                 [32, 128, 288, 288]       [32, 64, 288, 288]        73,728                    --\n",
      "│    │    └─MPConv: 3-90                 [32, 64, 288, 288]        [32, 64, 288, 288]        36,864                    --\n",
      "│    │    └─MPConv: 3-91                 [32, 128, 288, 288]       [32, 64, 288, 288]        8,192                     --\n",
      "├─MPConv: 1-3                            [32, 64, 288, 288]        [32, 2, 288, 288]         1,152                     --\n",
      "============================================================================================================================================\n",
      "Total params: 26,380,581\n",
      "Trainable params: 26,380,581\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.TERABYTES): 6.96\n",
      "============================================================================================================================================\n",
      "Input size (MB): 10.62\n",
      "Forward/backward pass size (MB): 54867.79\n",
      "Params size (MB): 105.52\n",
      "Estimated Total Size (MB): 54983.93\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, datefmt='%Y-%m-%d %H:%M:%S')\n",
    "device = torch.device('cpu')\n",
    "logging.info(f'using device: {device}')\n",
    "\n",
    "# ==================== Data ====================\n",
    "\n",
    "match model_name:\n",
    "    case 'UNet_e2eQPAT' | 'UNet_wl_pos_emb' | 'UNet_diffusion_ablation' | 'Swin_UNet':\n",
    "        example_input = torch.ones((8, 1, image_size, image_size))\n",
    "    case 'DDIM' | 'DiT':\n",
    "        raise NotImplementedError\n",
    "    case 'EDM2':\n",
    "        example_input = torch.ones((8, 2, image_size, image_size))\n",
    "        x_cond = torch.ones((8, 1, image_size, image_size))\n",
    "        t = torch.ones((8, 1))\n",
    "        wavelengths_one_hot = torch.ones((8, 1000))\n",
    "\n",
    "# ==================== Model ====================\n",
    "channels = 1\n",
    "out_channels = channels * 2 if predict_fluence else channels\n",
    "match model_name:\n",
    "    case 'UNet_e2eQPAT':\n",
    "        model = e2eQPAT_networks.RegressionUNet(\n",
    "            in_channels=channels, \n",
    "            out_channels=out_channels,\n",
    "            initial_filter_size=64, \n",
    "            kernel_size=3\n",
    "        )\n",
    "        if use_torchsummary:\n",
    "            summary(model, input_size=(8, channels, image_size, image_size), device='cpu', verbose=1, col_names=col_names)\n",
    "        if use_torchvista:\n",
    "            torchvista.trace_model(model, example_input)\n",
    "    case 'UNet_wl_pos_emb' | 'UNet_diffusion_ablation':\n",
    "        model = EDM2_UNet(\n",
    "            img_resolution=image_size,\n",
    "            img_channels_in=channels,\n",
    "            img_channels_out=out_channels,\n",
    "            label_dim=0,\n",
    "            model_channels=64,\n",
    "            attn_resolutions=[16, 8] if attention else [],\n",
    "            noise_emb=False,\n",
    "            num_blocks=1,\n",
    "            channel_mult=[1,2,4,8,16],\n",
    "        )\n",
    "        if use_torchsummary:\n",
    "            summary(model, input_size=(32, channels, image_size, image_size), device='cpu', verbose=1, col_names=col_names)\n",
    "        if use_torchvista:\n",
    "            torchvista.trace_model(model, example_input)\n",
    "    case 'Swin_UNet':\n",
    "        model = SwinTransformerSys(\n",
    "            img_size=image_size[0], patch_size=4, in_chans=channels, num_classes=out_channels,\n",
    "            embed_dim=96, depths=[2, 2, 2, 2], depths_decoder=[1, 2, 2, 2], num_heads=[3, 6, 12, 24],\n",
    "            window_size=8, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
    "            drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "            norm_layer=nn.LayerNorm, ape=False, patch_norm=False,\n",
    "            final_upsample=\"expand_first\"\n",
    "        )\n",
    "        uf.remove_softmax(model)\n",
    "    case 'DDIM':\n",
    "        model = ddp.Unet(\n",
    "            dim=32, channels=out_channels, out_dim=out_channels,\n",
    "            self_condition=True, image_condition=True, \n",
    "            image_condition_channels=channels, use_attn=attention,\n",
    "            full_attn=False, flash_attn=False\n",
    "        )\n",
    "        #model = TimeConditionedResUNet(\n",
    "        #    dim_in=out_channels, dim_out=out_channels, dim_first_layer=64,\n",
    "        #    kernel_size=3, theta_pos_emb=10000, self_condition=args.self_condition,\n",
    "        #    image_condition=True, dim_image_condition=channels\n",
    "        #)\n",
    "        diffusion = ddp.GaussianDiffusion(\n",
    "            # objecive='pred_v' predicts the velocity field, objective='pred_noise' predicts the noise\n",
    "            model, image_size=image_size, timesteps=1000,\n",
    "            sampling_timesteps=100, objective='pred_v', auto_normalize=False,\n",
    "        )\n",
    "    case 'DiT':\n",
    "        # parameters depth=12, hidden_size=384, and num_heads=6 are the same as DiT-S/8.\n",
    "        # with an image size of 256 and patch size of 16, we have the \n",
    "        # same number of patches as ViT from an image is worth 16x16 words\n",
    "        #if image_size[0] % 16 != 0:\n",
    "        #    raise ValueError('image size must be divisible by 16 for DiT model')\n",
    "        #patch_size = image_size[0] // 16\n",
    "        patch_size = 4\n",
    "        model = DiT(\n",
    "            dim_in=out_channels, dim_out=out_channels, input_size=image_size, \n",
    "            depth=12, hidden_size=384, patch_size=patch_size, num_heads=6,\n",
    "            self_condition=True, image_condition=True\n",
    "        )\n",
    "        diffusion = ddp.GaussianDiffusion(\n",
    "            # objecive='pred_v' predicts the velocity field, objective='pred_noise' predicts the noise\n",
    "            model, image_size=image_size, timesteps=1000,\n",
    "            sampling_timesteps=100, objective='pred_v', auto_normalize=False,\n",
    "        )\n",
    "    case 'EDM2':\n",
    "        attn_resolutions = [16, 8] if attention else []\n",
    "        in_channels = out_channels+1 # plus 1 for conditional information\n",
    "        loss_fn = EDM2Loss(P_mean=-0.8, P_std=1.6, sigma_data=0.5)\n",
    "        model = Precond(\n",
    "            img_resolution=image_size, img_channels_in=in_channels, img_channels_out=out_channels, #img_channels_in=in_channels, img_channels_out=out_channels,\n",
    "            label_dim=1000, model_channels=64, attn_resolutions=attn_resolutions, \n",
    "            use_fp16=False, sigma_data=0.5\n",
    "        )\n",
    "        model.unet.forward = partial(model.unet.forward, noise_labels=t.flatten(), class_labels=wavelengths_one_hot)\n",
    "        if use_torchsummary:\n",
    "            summary(model.unet, input_size=((8, in_channels, image_size, image_size)), device='cpu', verbose=1, col_names=col_names)\n",
    "        if use_torchvista:\n",
    "            torchvista.trace_model(model.unet, torch.cat([example_input, x_cond], dim=1), collapse_modules_after_depth=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
